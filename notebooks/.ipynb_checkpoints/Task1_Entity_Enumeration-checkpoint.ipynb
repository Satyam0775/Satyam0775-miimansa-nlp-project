{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505d61c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active code page: 1252\n",
      "Requirement already satisfied: transformers in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (4.56.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: torch in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: seqeval in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from transformers) (0.34.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\satya\\downloads\\miimansa problem\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets torch sentence-transformers scikit-learn seqeval pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from utils.data_loader import get_all_files, load_annotation_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ed1824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct base path for your dataset\n",
    "DATA_DIR = r\"C:\\Users\\satya\\Downloads\\Miimansa Problem\\Assignment\\data\\CADEC.v2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d0055ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total original files found: 1250\n",
      "First 5 files: ['C:\\\\Users\\\\satya\\\\Downloads\\\\Miimansa Problem\\\\Assignment\\\\data\\\\CADEC.v2\\\\original\\\\ARTHROTEC.1.ann', 'C:\\\\Users\\\\satya\\\\Downloads\\\\Miimansa Problem\\\\Assignment\\\\data\\\\CADEC.v2\\\\original\\\\ARTHROTEC.10.ann', 'C:\\\\Users\\\\satya\\\\Downloads\\\\Miimansa Problem\\\\Assignment\\\\data\\\\CADEC.v2\\\\original\\\\ARTHROTEC.100.ann', 'C:\\\\Users\\\\satya\\\\Downloads\\\\Miimansa Problem\\\\Assignment\\\\data\\\\CADEC.v2\\\\original\\\\ARTHROTEC.101.ann', 'C:\\\\Users\\\\satya\\\\Downloads\\\\Miimansa Problem\\\\Assignment\\\\data\\\\CADEC.v2\\\\original\\\\ARTHROTEC.102.ann']\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "# Base dataset path\n",
    "DATA_DIR = r\"C:\\Users\\satya\\Downloads\\Miimansa Problem\\Assignment\\data\\CADEC.v2\"\n",
    "\n",
    "# Look inside original folder for .ann files\n",
    "files = glob.glob(os.path.join(DATA_DIR, \"original\", \"*.ann\"))\n",
    "print(\"Total original files found:\", len(files))\n",
    "print(\"First 5 files:\", files[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6906cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils.data_loader as dl\n",
    "\n",
    "# Force reload the updated file\n",
    "importlib.reload(dl)\n",
    "\n",
    "from utils.data_loader import get_all_files, load_annotation_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f78c00a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 'T1\\tADR 9 19\\tbit drowsy\\n'\n",
      "1 '#1\\tAnnotatorNotes T1\\tDrowsy\\n'\n",
      "2 'T2\\tADR 29 50\\tlittle blurred vision\\n'\n",
      "3 '#2\\tAnnotatorNotes T2\\tBlurred Vision\\n'\n",
      "4 'T3\\tDrug 93 102\\tArthrotec\\n'\n",
      "5 'T5\\tDisease 179 188\\tarthritis\\n'\n",
      "6 'T6\\tSymptom 260 265\\tagony\\n'\n",
      "7 'T4\\tADR 62 78\\tgastric problems\\n'\n",
      "8 'T7\\tSymptom 412 417\\tpains\\n'\n",
      "9 'T8\\tADR 437 453\\tfeel a bit weird\\n'\n",
      "10 '#8\\tAnnotatorNotes T7\\tImplies a previous symptom of pain.\\n'\n"
     ]
    }
   ],
   "source": [
    "sample_file = r\"C:\\Users\\satya\\Downloads\\Miimansa Problem\\Assignment\\data\\CADEC.v2\\original\\ARTHROTEC.1.ann\"\n",
    "\n",
    "with open(sample_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(i, repr(line))\n",
    "        if i > 10:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf84f3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T1', 'ADR 9 19', 'bit drowsy\\n']\n",
      "['#1', 'AnnotatorNotes T1', 'Drowsy\\n']\n",
      "['T2', 'ADR 29 50', 'little blurred vision\\n']\n",
      "['#2', 'AnnotatorNotes T2', 'Blurred Vision\\n']\n",
      "['T3', 'Drug 93 102', 'Arthrotec\\n']\n",
      "['T5', 'Disease 179 188', 'arthritis\\n']\n",
      "['T6', 'Symptom 260 265', 'agony\\n']\n",
      "['T4', 'ADR 62 78', 'gastric problems\\n']\n",
      "['T7', 'Symptom 412 417', 'pains\\n']\n",
      "['T8', 'ADR 437 453', 'feel a bit weird\\n']\n",
      "['#8', 'AnnotatorNotes T7', 'Implies a previous symptom of pain.\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(sample_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        print(repr(line.split(\"\\t\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e7efd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed: [('T1', 'ADR', '9 19', 'bit drowsy'), ('T2', 'ADR', '29 50', 'little blurred vision'), ('T3', 'Drug', '93 102', 'Arthrotec'), ('T5', 'Disease', '179 188', 'arthritis'), ('T6', 'Symptom', '260 265', 'agony'), ('T4', 'ADR', '62 78', 'gastric problems'), ('T7', 'Symptom', '412 417', 'pains'), ('T8', 'ADR', '437 453', 'feel a bit weird')]\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = r\"C:\\Users\\satya\\Downloads\\Miimansa Problem\\Assignment\\data\\CADEC.v2\"\n",
    "sample_file = os.path.join(DATA_DIR, \"original\", \"ARTHROTEC.1.ann\")\n",
    "parsed = load_annotation_file(sample_file)\n",
    "print(\"Parsed:\", parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\satya\\Downloads\\Miimansa Problem\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text snippet:\n",
      " I feel a bit drowsy & have a little blurred vision, so far no gastric problems.\n",
      "I've been on Arthrotec 50 for over 10 years on and off, only taking it when I needed it.\n",
      "Due to my arthritis getting pro ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw model predictions (first few):\n",
      "{'entity_group': 'Sign_symptom', 'score': np.float32(0.99989974), 'word': 'dr', 'start': 13, 'end': 15}\n",
      "{'entity_group': 'Sign_symptom', 'score': np.float32(0.9951048), 'word': '##owsy', 'start': 15, 'end': 19}\n",
      "{'entity_group': 'Sign_symptom', 'score': np.float32(0.7793145), 'word': 'blurred', 'start': 36, 'end': 43}\n",
      "{'entity_group': 'Detailed_description', 'score': np.float32(0.96931857), 'word': 'art', 'start': 93, 'end': 96}\n",
      "{'entity_group': 'Therapeutic_procedure', 'score': np.float32(0.54796815), 'word': '##hrotec', 'start': 96, 'end': 102}\n",
      "\n",
      "CADEC-style predictions (sample):\n",
      "('T1', 'ADR', '13 15', 'dr')\n",
      "('T2', 'ADR', '15 19', 'owsy')\n",
      "('T3', 'ADR', '36 43', 'blurred')\n",
      "('T4', 'Symptom', '93 96', 'art')\n",
      "('T5', 'Symptom', '96 102', 'hrotec')\n",
      "('T6', 'Symptom', '103 105', '50')\n",
      "('T7', 'Symptom', '110 123', 'over 10 years')\n",
      "('T8', 'Disease', '179 188', 'arthritis')\n",
      "('T9', 'Symptom', '286 288', '75')\n",
      "('T10', 'Symptom', '289 300', 'twice a day')\n",
      "\n",
      "✅ Saved predictions:\n",
      "- C:\\Users\\satya\\Downloads\\Miimansa Problem\\Assignment\\outputs\\task2\\ARTHROTEC.1.pred.ann\n",
      "- C:\\Users\\satya\\Downloads\\Miimansa Problem\\Assignment\\outputs\\task2\\ARTHROTEC.1_predictions.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import nltk\n",
    "from transformers import pipeline\n",
    "\n",
    "# -------------------------------\n",
    "# Setup paths\n",
    "# -------------------------------\n",
    "DATA_DIR = r\"C:\\Users\\satya\\Downloads\\Miimansa Problem\\Assignment\\data\\CADEC.v2\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\satya\\Downloads\\Miimansa Problem\\Assignment\\outputs\\task2\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Example file to test\n",
    "filename = \"ARTHROTEC.1\"\n",
    "text_file = os.path.join(DATA_DIR, \"text\", f\"{filename}.txt\")\n",
    "\n",
    "with open(text_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read().strip()\n",
    "\n",
    "print(\"Sample text snippet:\\n\", text[:200], \"...\")\n",
    "\n",
    "# -------------------------------\n",
    "# Load Biomedical NER model\n",
    "# -------------------------------\n",
    "ner = pipeline(\"ner\", model=\"d4data/biomedical-ner-all\", aggregation_strategy=\"simple\")\n",
    "\n",
    "results = ner(text)\n",
    "\n",
    "print(\"\\nRaw model predictions (first few):\")\n",
    "for r in results[:5]:\n",
    "    print(r)\n",
    "\n",
    "# -------------------------------\n",
    "# Map HuggingFace labels to CADEC labels\n",
    "# -------------------------------\n",
    "label_map = {\n",
    "    \"Sign_symptom\": \"ADR\",\n",
    "    \"Disease_disorder\": \"Disease\",\n",
    "    \"Drug\": \"Drug\",\n",
    "    \"Detailed_description\": \"Symptom\",\n",
    "    \"Therapeutic_procedure\": \"Symptom\",\n",
    "    \"Dosage\": \"Symptom\",\n",
    "    \"Duration\": \"Symptom\",\n",
    "    \"Frequency\": \"Symptom\",\n",
    "    \"Lab_value\": \"Symptom\",\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# Convert predictions to CADEC-style .ann format\n",
    "# -------------------------------\n",
    "annotations = []\n",
    "tid = 1\n",
    "for r in results:\n",
    "    start, end = r[\"start\"], r[\"end\"]\n",
    "    ent_text = text[start:end].lower()\n",
    "    mapped_label = label_map.get(r[\"entity_group\"], None)\n",
    "    if not mapped_label:\n",
    "        continue\n",
    "    annotations.append((f\"T{tid}\", mapped_label, f\"{start} {end}\", ent_text))\n",
    "    tid += 1\n",
    "\n",
    "print(\"\\nCADEC-style predictions (sample):\")\n",
    "for ann in annotations[:10]:\n",
    "    print(ann)\n",
    "\n",
    "# -------------------------------\n",
    "# Save outputs\n",
    "# -------------------------------\n",
    "# Save .pred.ann\n",
    "pred_file = os.path.join(OUTPUT_DIR, f\"{filename}.pred.ann\")\n",
    "with open(pred_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for tid, label, span, ent_text in annotations:\n",
    "        f.write(f\"{tid}\\t{label} {span}\\t{ent_text}\\n\")\n",
    "\n",
    "# Save JSON\n",
    "pred_json = os.path.join(OUTPUT_DIR, f\"{filename}_predictions.json\")\n",
    "with open(pred_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(\n",
    "        [{\"id\": tid, \"label\": label, \"span\": span, \"text\": ent_text}\n",
    "         for tid, label, span, ent_text in annotations],\n",
    "        f,\n",
    "        indent=2\n",
    "    )\n",
    "\n",
    "print(f\"\\n✅ Saved predictions:\\n- {pred_file}\\n- {pred_json}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
